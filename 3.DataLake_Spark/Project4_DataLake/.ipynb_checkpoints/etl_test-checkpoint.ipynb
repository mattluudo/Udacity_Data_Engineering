{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 1. INITIALIZE CONFIGURATION VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 2. CREATE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 3. READ INPUT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3a. EXTRACT LOCAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-data.zip\n",
      "song-data.zip\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.zip'):\n",
    "        file_name = file.split('.')[0]\n",
    "        with ZipFile('data/' + file) as zp:\n",
    "            zp.extractall('extracted_data/' + file_name)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3b. READ LOCAL INPUT DATA FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "local_song_path = config['LOCAL']['SONG_DATA_PATH']\n",
    "local_log_path = config['LOCAL']['LOG_DATA_PATH']\n",
    "local_song_data = spark.read.json(local_song_path)\n",
    "local_log_data = spark.read.json(local_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  71\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "[Row(artist_id='ARDR4AC1187FB371A1', artist_latitude=None, artist_location='', artist_longitude=None, artist_name='Montserrat Caball√©;Placido Domingo;Vicente Sardinero;Judith Blegen;Sherrill Milnes;Georg Solti', duration=511.16363, num_songs=1, song_id='SOBAYLL12A8C138AF9', title='Sono andati? Fingevo di dormire', year=0)]\n",
      "\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|     artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                    |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|         Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|   Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|        New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARNF6401187FB57032|       40.79086|New York, NY [Man...|       -73.96644|   Sophie B. Hawkins|  305.162|        1|SONWXQJ12A8C134D94|The Ballad Of Sle...|1994|\n",
      "|ARDNS031187B9924F0|       32.67828|             Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "|ARLTWXK1187FB5A3F8|       32.74863|      Fort Worth, TX|       -97.32925|         King Curtis|326.00771|        1|SODREIN12A58A7F2E5|A Whiter Shade Of...|   0|\n",
      "|ARPFHN61187FB575F6|       41.88415|         Chicago, IL|       -87.63241|         Lupe Fiasco|279.97995|        1|SOWQTQZ12A58A7B63E|Streets On Fire (...|   0|\n",
      "|ARI2JSK1187FB496EF|       51.50632|     London, England|        -0.12714|Nick Ingman;Gavyn...|111.62077|        1|SODUJBS12A8C132150|Wessex Loses a Bride|   0|\n",
      "|AR9AWNF1187B9AB0B4|           null|Seattle, Washingt...|            null|Kenny G featuring...|236.93016|        1|SOZHPGD12A8C1394FE|     Baby Come To Me|   0|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Count: \", local_song_data.count())\n",
    "local_song_data.printSchema()\n",
    "print(local_song_data.take(1)), print()\n",
    "local_song_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  8056\n",
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n",
      "[Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', itemInSession=0, lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Sehr kosmisch', status=200, ts=1542241826796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26')]\n",
      "\n",
      "+-----------+----------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|     artist|      auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-----------+----------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|   Harmonia| Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "|The Prodigy| Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|     The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|\n",
      "|      Train| Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|            Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|\n",
      "|       null| Logged In|    Wyatt|     M|            0|   Scott|     null| free|Eureka-Arcata-For...|   GET|    Home|1.540872073796E12|      563|                null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|\n",
      "|       null| Logged In|   Austin|     M|            0| Rosales|     null| free|New York-Newark-J...|   GET|    Home|1.541059521796E12|      521|                null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|\n",
      "|Sony Wonder| Logged In|   Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|1.540492941796E12|      597|           Blackbird|   200|1542253449796|\"Mozilla/5.0 (Mac...|    61|\n",
      "|       null| Logged In|   Samuel|     M|            1|Gonzalez|     null| free|Houston-The Woodl...|   GET|   About|1.540492941796E12|      597|                null|   200|1542253460796|\"Mozilla/5.0 (Mac...|    61|\n",
      "|       null|Logged Out|     null|  null|            0|    null|     null| paid|                null|   PUT|   Login|             null|      602|                null|   307|1542260074796|                null|      |\n",
      "|       null| Logged In|    Tegan|     F|            1|  Levine|     null| paid|Portland-South Po...|   GET|    Home|1.540794356796E12|      602|                null|   200|1542260277796|\"Mozilla/5.0 (Mac...|    80|\n",
      "|  Van Halen| Logged In|    Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|1.540794356796E12|      602|Best Of Both Worl...|   200|1542260935796|\"Mozilla/5.0 (Mac...|    80|\n",
      "+-----------+----------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Count: \", local_log_data.count())\n",
    "local_log_data.printSchema()\n",
    "print(local_log_data.take(1)), print()\n",
    "local_log_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3c. READ DATA FROM S3 FOR PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3a://udacity-dend/song_data/A/A/A/TRAAAAW128F429D538.json',\n",
       " 's3a://udacity-dend/log-data/*/*/*.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.read('dl.cfg')\n",
    "aws_song_path = config['AWS']['SONG_DATA_PATH']\n",
    "aws_log_path = config['AWS']['LOG_DATA_PATH']\n",
    "config['AWS']['SONG_DATA_PATH'], config['AWS']['LOG_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4abac3093749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maws_log_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AWS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOG_DATA_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maws_song_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AWS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SONG_DATA_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "aws_log_data = spark.read.format(\"json\").load(config['AWS']['LOG_DATA_PATH'])\n",
    "aws_song_data = spark.read.format(\"json\").load(config['AWS']['SONG_DATA_PATH'])\n",
    "print(time.time() - start, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Count: \", aws_song_data.count())\n",
    "aws_song_data.printSchema()\n",
    "print(aws_song_data.take(1)), print()\n",
    "aws_song_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Count: \", aws_log_data.count())\n",
    "aws_log_data.printSchema()\n",
    "print(aws_log_data.take(1)), print()\n",
    "aws_log_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 4. CREATE TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SWITCH LINES FOR LOCAL VS AWS USE\n",
    "\n",
    "song_data = local_song_data\n",
    "log_data = local_log_data\n",
    "output_path = config['LOCAL']['OUTPUT_DATA_PATH']\n",
    "\n",
    "# song_data = aws_song_data\n",
    "# log_data = aws_log_data\n",
    "# output_path = config['AWS']['OUTPUT_DATA_PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4a. CREATE SONGS TABLE FROM SONG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_data.createOrReplaceTempView(\"song_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  71\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      "\n",
      "[Row(song_id='SOAOIBZ12AB01815BE', title='I Hold Your Hand In Mine [Live At Royal Albert Hall]', artist_id='ARPBNLO1187FB3D52F', year=2000, duration=43.36281)]\n",
      "\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOAOIBZ12AB01815BE|I Hold Your Hand ...|ARPBNLO1187FB3D52F|2000| 43.36281|\n",
      "|SOBAYLL12A8C138AF9|Sono andati? Fing...|ARDR4AC1187FB371A1|   0|511.16363|\n",
      "|SOBBUGU12A8C13E95D|Setting Fire to S...|ARMAC4T1187FB3FA4C|2004|207.77751|\n",
      "|SOBBXLX12A58A79DDA|Erica (2005 Digit...|AREDBBQ1187B98AFF5|   0|138.63138|\n",
      "|SOBCOSW12A8C13D398|  Rumba De Barcelona|AR7SMBG1187B9B9066|   0|218.38322|\n",
      "|SOBEBDG12A58A76D60|        Kassie Jones|ARI3BMM1187FB4255E|   0|220.78649|\n",
      "|SOBKWDJ12A8C13B2F3|Wild Rose (Back 2...|AR36F9J1187FB406F1|   0|230.71302|\n",
      "|SOBLGCN12AB0183212|James (Hold The L...|AR47JEX1187B995D81|1985|124.86485|\n",
      "|SOBONFF12A6D4F84D8|Tonight Will Be A...|ARIK43K1187B9AE54C|1986| 307.3824|\n",
      "|SOBZBAZ12A6D4F8742|      Spanish Grease|AROUOZZ1187B9ABE51|1997|168.25424|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table = spark.sql(\"\"\"\n",
    "    SELECT song_id, title, artist_id, year, duration\n",
    "    FROM song_data\n",
    "    ORDER BY song_id\n",
    "\"\"\")\n",
    "print(\"Count: \", songs_table.count())\n",
    "songs_table.printSchema()\n",
    "print(songs_table.take(1)), print()\n",
    "songs_table.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.write.mode(\"overwrite\")\\\n",
    "                 .partitionBy(\"year\", \"artist_id\")\\\n",
    "                 .parquet(output_path + 'songs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4b. CREATE ARTISTS TABLE FROM SONG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  69\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      "\n",
      "[Row(artist_id='ARYKCQI1187FB3B18F', artist_name='Tesla', artist_location='', artist_latitude=None, artist_longitude=None)]\n",
      "\n",
      "+------------------+------------------+---------------+---------------+----------------+\n",
      "|         artist_id|       artist_name|artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+------------------+---------------+---------------+----------------+\n",
      "|ARYKCQI1187FB3B18F|             Tesla|               |           null|            null|\n",
      "|ARXR32B1187FB57099|               Gob|               |           null|            null|\n",
      "|ARWB3G61187FB49404|       Steve Morse| Hamilton, Ohio|           null|            null|\n",
      "|ARVBRGZ1187FB4675A|      Gwen Stefani|               |           null|            null|\n",
      "|ARULZCI1241B9C8611|Luna Orbit Project|               |           null|            null|\n",
      "|ARQGYP71187FB44566|      Jimmy Wakely|    Mineola, AR|       34.31109|       -94.02978|\n",
      "|ARQ9BO41187FB5CF1F|        John Davis|   Pennsylvania|       40.99471|       -77.60454|\n",
      "|ARPFHN61187FB575F6|       Lupe Fiasco|    Chicago, IL|       41.88415|       -87.63241|\n",
      "|ARPBNLO1187FB3D52F|          Tiny Tim|   New York, NY|       40.71455|       -74.00712|\n",
      "|ARP6N5A1187B99D1A3|       Mitch Ryder|  Hamtramck, MI|           null|            null|\n",
      "+------------------+------------------+---------------+---------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT artist_id, \n",
    "                    artist_name AS name, \n",
    "                    artist_location AS location, \n",
    "                    artist_latitude AS latitude, \n",
    "                    artist_longitude AS longitude\n",
    "    FROM song_data\n",
    "    ORDER BY artist_id desc\n",
    "\"\"\")\n",
    "print(\"Count: \", artists_table.count())\n",
    "artists_table.printSchema()\n",
    "print(artists_table.take(1)), print()\n",
    "artists_table.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_table.write.mode(\"overwrite\").parquet(output_path + 'artists/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4c. CREATE TIME TABLE FROM LOG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, to_date\n",
    "from pyspark.sql import types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "MILLISECONDS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "extract_timestamp = udf(lambda x: datetime.fromtimestamp(x / MILLISECONDS), t.TimestampType())\n",
    "log_data = log_data.withColumn(\"timestamp\", extract_timestamp(log_data.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data.createOrReplaceTempView(\"log_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  8023\n",
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "[Row(datetime=datetime.datetime(2018, 11, 1, 20, 57, 10, 796000), hour=20, day=1, week=44, month=11, year=2018, weekday=5)]\n",
      "\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|            datetime|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-01 20:57:...|  20|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:01:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:02:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:05:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:08:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:11:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:17:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:24:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:28:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:42:...|  21|  1|  44|   11|2018|      5|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT  timestamp AS start_time,\n",
    "                     hour(timestamp) AS hour,\n",
    "                     day(timestamp)  AS day,\n",
    "                     weekofyear(timestamp) AS week,\n",
    "                     month(timestamp) AS month,\n",
    "                     year(timestamp) AS year,\n",
    "                     dayofweek(timestamp) AS weekday\n",
    "    FROM log_data\n",
    "    ORDER BY datetime\n",
    "\"\"\")\n",
    "print(\"Count: \", time_table.count())\n",
    "time_table.printSchema()\n",
    "print(time_table.take(1)), print()\n",
    "time_table.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.write.mode(\"overwrite\")\\\n",
    "                .partitionBy(\"year\", \"month\")\\\n",
    "                .parquet(output_path + 'time/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4d. CREATE USERS TABLE FROM LOG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  107\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "[Row(user_id='', first_name=None, last_name=None, gender=None, level='free')]\n",
      "\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|       |      null|     null|  null| free|\n",
      "|       |      null|     null|  null| paid|\n",
      "|     66|     Kevin| Arellano|     M| free|\n",
      "|     34|    Evelin|    Ayala|     F| free|\n",
      "|     99|       Ann|    Banks|     F| free|\n",
      "|    100|     Adler|  Barrera|     M| free|\n",
      "|     42|    Harper|  Barrett|     M| paid|\n",
      "|     91|    Jayden|     Bell|     M| free|\n",
      "|      2|   Jizelle| Benjamin|     F| free|\n",
      "|     58|     Emily|   Benson|     F| paid|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_table = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT userId    AS user_id, \n",
    "                     firstName AS first_name, \n",
    "                     lastName  AS last_name, \n",
    "                     gender, \n",
    "                     level\n",
    "    FROM log_data\n",
    "    ORDER BY last_name\n",
    "\"\"\")\n",
    "\n",
    "print(\"Count: \", users_table.count())\n",
    "users_table.printSchema()\n",
    "print(users_table.take(1)), print()\n",
    "users_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.mode(\"overwrite\").parquet(output_path + 'users/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4e. CREATE SONGPLAYS TABLE FROM LOG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  21\n",
      "root\n",
      " |-- songplay_id: long (nullable = false)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      "\n",
      "[Row(songplay_id=0, start_time=datetime.datetime(2018, 11, 15, 20, 32, 47, 796000), user_id='44', level='paid', song_id='SOBONFF12A6D4F84D8', artist_id='ARIK43K1187B9AE54C', session_id=619, location='Waterloo-Cedar Falls, IA', user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0')]\n",
      "\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|songplay_id|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|          0|2018-11-15 20:32:...|     44| paid|SOBONFF12A6D4F84D8|ARIK43K1187B9AE54C|       619|Waterloo-Cedar Fa...|Mozilla/5.0 (Maci...|\n",
      "|          1|2018-11-21 21:56:...|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|\n",
      "|          2|2018-11-14 13:11:...|     34| free|SOWQTQZ12A58A7B63E|ARPFHN61187FB575F6|       495|Milwaukee-Waukesh...|Mozilla/5.0 (Maci...|\n",
      "|          3|2018-11-14 20:16:...|    101| free|SORRZGD12A6310DBC3|ARVBRGZ1187FB4675A|       603|New Orleans-Metai...|\"Mozilla/5.0 (Win...|\n",
      "|          4|2018-11-28 23:22:...|     24| paid|SOWQTQZ12A58A7B63E|ARPFHN61187FB575F6|       984|Lake Havasu City-...|\"Mozilla/5.0 (Win...|\n",
      "|          5|2018-11-24 03:48:...|     88| paid|SONWXQJ12A8C134D94|ARNF6401187FB57032|       888|Sacramento--Rosev...|\"Mozilla/5.0 (Mac...|\n",
      "|          6|2018-11-24 12:42:...|     80| paid|SOBONFF12A6D4F84D8|ARIK43K1187B9AE54C|       903|Portland-South Po...|\"Mozilla/5.0 (Mac...|\n",
      "|          7|2018-11-29 20:29:...|     49| paid|SOBONFF12A6D4F84D8|ARIK43K1187B9AE54C|      1041|San Francisco-Oak...|Mozilla/5.0 (Wind...|\n",
      "|          8|2018-11-19 15:36:...|     49| paid|SOFSOCN12A8C143F5D|ARXR32B1187FB57099|       724|San Francisco-Oak...|Mozilla/5.0 (Wind...|\n",
      "|          9|2018-11-19 20:44:...|     42| paid|SOFFKZS12AB017F194|ARBEBBY1187B9B43DB|       632|New York-Newark-J...|\"Mozilla/5.0 (Win...|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table = spark.sql(\"\"\"\n",
    "    SELECT  log_data.timestamp AS start_time, \n",
    "            log_data.userId AS user_id, \n",
    "            log_data.level, \n",
    "            song_data.song_id, \n",
    "            song_data.artist_id ,\n",
    "            log_data.sessionId AS session_id, \n",
    "            log_data.location, \n",
    "            log_data.userAgent AS user_agent\n",
    "\n",
    "    FROM log_data \n",
    "    INNER JOIN song_data \n",
    "    ON song_data.artist_name = log_data.artist \n",
    "    WHERE log_data.page = 'NextSong'\n",
    "\"\"\")\n",
    "songplays_table = songplays_table.withColumn(\"songplay_id\", monotonically_increasing_id())\n",
    "songplays_table = songplays_table.select('songplay_id', *songplays_table.columns[:len(songplays_table.columns)-1])\n",
    "\n",
    "print(\"Count: \", songplays_table.count())\n",
    "songplays_table.printSchema()\n",
    "print(songplays_table.take(1)), print()\n",
    "songplays_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.write.mode(\"overwrite\").parquet(output_path + 'song_plays/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
